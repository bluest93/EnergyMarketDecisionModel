{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f25e270",
   "metadata": {},
   "source": [
    "# Energy Market Forecasting and Trading Decision Model\n",
    "\n",
    "This notebook presents a **data-driven decision support system** for intraday energy trading, developed in accordance with the [TASK.pdf](./TASK.pdf).  \n",
    "The project focuses on predicting the **expected settlement price** in the Nordic balancing market and using this forecast to guide trading actions (BUY / SELL / HOLD).  \n",
    "The evaluation then estimates the **expected profit** from these decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal is to forecast the **expected settlement price** for the delivery hour (17:00–18:00), based on market information available at **16:53**.  \n",
    "From this expectation, we determine whether the trader should **buy**, **sell**, or **hold** a position.\n",
    "\n",
    "The model first estimates the **probability** that the system regulation will be *positive* (the market being short).  \n",
    "Given this probability $ p_{\\text{pos}} $, the expected settlement price is calculated as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[P_{\\text{settlement}}] = p_{\\text{pos}} \\times 90 + (1 - p_{\\text{pos}}) \\times 0,\n",
    "$$\n",
    "\n",
    "where:\n",
    "- €90  represents the settlement price if the system is short (positive regulation),\n",
    "- €0  represents the price if the system is long (negative regulation).\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Logic\n",
    "\n",
    "Once the expected settlement price is estimated, the trading action is determined by comparing it to the **market bid/offer price** (≈ 30 €):\n",
    "\n",
    "$$\n",
    "\\text{Decision} =\n",
    "\\begin{cases}\n",
    "\\text{BUY}, & \\text{if } \\mathbb{E}[P_{\\text{settlement}}] > 30,\\\\\n",
    "\\text{SELL}, & \\text{if } \\mathbb{E}[P_{\\text{settlement}}] < 30,\\\\\n",
    "\\text{HOLD}, & \\text{if } \\mathbb{E}[P_{\\text{settlement}}] = 30.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This ensures that actions are made **before** the delivery period, based purely on forecasted expectations.\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Profit (Evaluation Phase)\n",
    "\n",
    "After the decision is made, we evaluate the **expected profit** from each strategy as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\pi_{\\text{buy}}] = p_{\\text{pos}}(90 - 30) + (1 - p_{\\text{pos}})(0 - 30),\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}[\\pi_{\\text{sell}}] = p_{\\text{pos}}(30 - 90) + (1 - p_{\\text{pos}})(30 - 0).\n",
    "$$\n",
    "\n",
    "The profit formulas are not used during decision-making — only for **post-hoc analysis** to evaluate the model’s trading performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4542579-a3bd-44ee-8bc2-4eb87635ec07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "# Filter out specific warning message\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe03ed9",
   "metadata": {},
   "source": [
    "loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e597ba3-ea47-4c4a-8824-891eb2516eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "df.rename(columns={'val': 'regulation_mw'}, inplace=True)\n",
    "df.rename(columns={'utc': 'datetime'}, inplace=True)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], utc=True)\n",
    "df = df.sort_index() # make sure it is in correct time dirction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd78a0b6-49b6-43bb-abb5-7d87989f79bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [datetime, regulation_mw]\n",
      "Index: []\n",
      "Training samples: 412\n",
      "Positive cases: 209 (50.7%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_ml_features(df, target_time):\n",
    "    \"\"\"\n",
    "    Create features for predicting whether 17:00-18:00 sum will be positive\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    targets = []\n",
    "    \n",
    "    # For each historical day at 16:53\n",
    "    for date in df['datetime'].dt.date.unique():  # Exclude today\n",
    "        \n",
    "        # Point in time: 16:54 on that date\n",
    "        cutoff = pd.Timestamp(date).tz_localize('UTC') + pd.Timedelta(hours=16, minutes=53)\n",
    "        delivery_start = pd.Timestamp(date).tz_localize('UTC') + pd.Timedelta(hours=17)\n",
    "        delivery_end = pd.Timestamp(date).tz_localize('UTC') + pd.Timedelta(hours=18)\n",
    "        \n",
    "        # Only use data available at 16:54\n",
    "        available_data = df[(df['datetime'].dt.date == date) & (df['datetime'] <= cutoff)]\n",
    "        \n",
    "        \n",
    "        delivery_data = df[(df['datetime'] >= delivery_start) & \n",
    "                          (df['datetime'] < delivery_end)]\n",
    "        if date == pd.Timestamp('2021-02-16').date():\n",
    "            print(delivery_data)\n",
    "        # FEATURES (what we know at 16:54)\n",
    "        feat = {\n",
    "            # Current state\n",
    "            'current_reg': available_data.iloc[-1]['regulation_mw'],\n",
    "            'reg_5min_ago': available_data.iloc[-5]['regulation_mw'] if len(available_data) > 5 else 0,\n",
    "            'reg_10min_ago': available_data.iloc[-10]['regulation_mw'] if len(available_data) > 10 else 0,\n",
    "            \n",
    "            # Recent trends\n",
    "            'last_5min_mean': available_data.tail(5)['regulation_mw'].mean(),\n",
    "            'last_10min_mean': available_data.tail(10)['regulation_mw'].mean(),\n",
    "            'last_30min_mean': available_data.tail(30)['regulation_mw'].mean(),\n",
    "            'last_60min_mean': available_data.tail(60)['regulation_mw'].mean(),\n",
    "            \n",
    "            \n",
    "            # Momentum\n",
    "            'momentum_10min': available_data.tail(10)['regulation_mw'].mean() - \n",
    "                             available_data.tail(20).head(10)['regulation_mw'].mean(),\n",
    "            \n",
    "            # Time features\n",
    "            'weekday': pd.Timestamp(date).weekday(),\n",
    "            'is_monday': 1 if pd.Timestamp(date).weekday() == 0 else 0,\n",
    "            'is_friday': 1 if pd.Timestamp(date).weekday() == 4 else 0,\n",
    "            \n",
    "            # Today's pattern\n",
    "            'morning_avg': df[(df['datetime'].dt.date == date) & \n",
    "                             (df['datetime'].dt.hour < 12)]['regulation_mw'].mean(),\n",
    "            'afternoon_avg': df[(df['datetime'].dt.date == date) & \n",
    "                              (df['datetime'].dt.hour >= 12) & \n",
    "                              (df['datetime'].dt.hour < 17)]['regulation_mw'].mean(),\n",
    "            \n",
    "            # Volatility\n",
    "            'last_5min_volatility': available_data.tail(5)['regulation_mw'].std(),\n",
    "            'last_10min_volatility': available_data.tail(10)['regulation_mw'].std(),\n",
    "            'last_60min_volatility': available_data.tail(60)['regulation_mw'].std(),\n",
    "            \n",
    "            # Extreme indicators\n",
    "            'recent_max': available_data.tail(60)['regulation_mw'].max(),\n",
    "            'recent_min': available_data.tail(60)['regulation_mw'].min(),\n",
    "        }\n",
    "        \n",
    "        # TARGET: Was the sum positive?\n",
    "        target = 1 if delivery_data['regulation_mw'].sum() > 0 else 0\n",
    "        \n",
    "        features.append(feat)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return pd.DataFrame(features[:-1]), np.array(targets[:-1]), pd.DataFrame([features[-1]])\n",
    "\n",
    "# Prepare training data\n",
    "current_time = '2021-02-16 16:54:00' \n",
    "X, y, pred_X = prepare_ml_features(df, current_time)\n",
    "\n",
    "print(f\"Training samples: {len(X)}\")\n",
    "print(f\"Positive cases: {y.sum()} ({y.mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f40fd28-12e1-48e3-a6a7-67de83feed63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_idx = int(len(X) * 0.7)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef1a5ba-7291-4dd5-b44e-222f0494f320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "results = {}\n",
    "# 1. Logistic Regression\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "logreg_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results['Logistic Regression'] = {\n",
    "    'predictions': logreg_pred,\n",
    "    'accuracy': accuracy_score(y_test, logreg_pred),\n",
    "    'precision': precision_score(y_test, logreg_pred),\n",
    "    'recall': recall_score(y_test, logreg_pred),\n",
    "    'f1': f1_score(y_test, logreg_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, logreg_proba),\n",
    "    'log_loss': log_loss(y_test, logreg_proba)\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results['XGBoost Classifier'] = {\n",
    "    'predictions': xgb_pred,\n",
    "    'accuracy': accuracy_score(y_test, xgb_pred),\n",
    "    'precision': precision_score(y_test, xgb_pred),\n",
    "    'recall': recall_score(y_test, xgb_pred),\n",
    "    'f1': f1_score(y_test, xgb_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, xgb_proba),\n",
    "    'log_loss': log_loss(y_test, xgb_proba)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219283a",
   "metadata": {},
   "source": [
    "`accuracy`: Overall proportion of correct predictions.\n",
    "\n",
    "`precision`: Of all predicted positives, how many were actually positive (Good for avoiding false positives.)\n",
    "\n",
    "`recall`: Of all actual positives, how many did you correctly identify (Good for avoiding false negatives.)\n",
    "\n",
    "`f1`: Harmonic mean of precision and recall — balances both.\n",
    "\n",
    "`roc_auc`: Measures how well the model separates classes across all thresholds. Higher is better.\n",
    "\n",
    "`log_loss`: Penalizes incorrect confident predictions — lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628d1aec-36de-49f9-95c3-26125e31e729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "  Accuracy:   0.669\n",
      "  Precision:  0.685\n",
      "  Recall:     0.735\n",
      "  F1 Score:   0.709\n",
      "  ROC AUC:    0.660\n",
      "  Log Loss:   0.6380\n",
      "\n",
      "XGBoost Classifier:\n",
      "  Accuracy:   0.565\n",
      "  Precision:  0.617\n",
      "  Recall:     0.544\n",
      "  F1 Score:   0.578\n",
      "  ROC AUC:    0.561\n",
      "  Log Loss:   0.9913\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy:   {metrics['accuracy']:.3f}\")\n",
    "    print(f\"  Precision:  {metrics['precision']:.3f}\")\n",
    "    print(f\"  Recall:     {metrics['recall']:.3f}\")\n",
    "    print(f\"  F1 Score:   {metrics['f1']:.3f}\")\n",
    "    print(f\"  ROC AUC:    {metrics['roc_auc']:.3f}\")\n",
    "    print(f\"  Log Loss:   {metrics['log_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42310102",
   "metadata": {},
   "source": [
    "Since Logistic Regression performs better in this case, we will use it to train on the entire dataset and make predictions for 2021-02-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f349c7f-9825-448d-a94e-cdd77486bde0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X, y)\n",
    "logreg_pred = logreg.predict(pred_X)\n",
    "logreg_proba = logreg.predict_proba(pred_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2afb6d3a-22b3-40a7-818f-43da9eab1dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.69104\n",
      "[100]\tvalidation_0-logloss:0.57174\n",
      "[200]\tvalidation_0-logloss:0.51509\n",
      "[300]\tvalidation_0-logloss:0.48135\n",
      "[400]\tvalidation_0-logloss:0.45467\n",
      "[499]\tvalidation_0-logloss:0.43021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = XGBClassifier(\n",
    "#     objective='binary:logistic',\n",
    "#     n_estimators=500,\n",
    "#     learning_rate=0.01,\n",
    "#     max_depth=3,\n",
    "#     early_stopping_rounds=100,\n",
    "#     random_state=42\n",
    "# )\n",
    "# model.fit(X, y,\n",
    "#           eval_set=[(X, y)],\n",
    "#         verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7743f2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model probability: 0.52\n",
      "Expected settlement: €46.39\n",
      "Decision: BUY | Expected profit: €16.39/MWh\n"
     ]
    }
   ],
   "source": [
    "def trading_decision(prob_pos, buy_price=30.0, sell_price=30.0, high_settlement=90.0, low_settlement=0.0):\n",
    "    \n",
    "\n",
    "    # Expected settlement price (weighted by probability)\n",
    "    expected_settlement = prob_pos * high_settlement + (1 - prob_pos) * low_settlement\n",
    "\n",
    "    # Decision logic\n",
    "    if expected_settlement > buy_price:\n",
    "        action = \"BUY\"\n",
    "        expected_profit = expected_settlement - buy_price\n",
    "    elif expected_settlement < sell_price:\n",
    "        action = \"SELL\"\n",
    "        expected_profit = sell_price - expected_settlement\n",
    "    else:\n",
    "        action = \"HOLD\"\n",
    "        expected_profit = 0.0\n",
    "\n",
    "    return action, expected_profit, expected_settlement\n",
    "\n",
    "p_pos = logreg_proba \n",
    "action, profit, exp_price = trading_decision(logreg_proba)\n",
    "\n",
    "print(f\"Model probability: {p_pos[0]:.2f}\")\n",
    "print(f\"Expected settlement: €{exp_price[0]:.2f}\")\n",
    "print(f\"Decision: {action} | Expected profit: €{profit[0]:.2f}/MWh\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f7163",
   "metadata": {},
   "source": [
    "Also we can see which features are more important in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf2ad52-c137-4ac5-9caf-0baa365d7719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekday                  0.029867\n",
      "last_10min_mean          0.028781\n",
      "is_monday                0.012666\n",
      "reg_5min_ago             0.011081\n",
      "last_60min_mean          0.007881\n",
      "morning_avg              0.006584\n",
      "reg_10min_ago            0.006460\n",
      "is_friday                0.005468\n",
      "last_30min_mean          0.004865\n",
      "last_5min_mean           0.004390\n",
      "last_60min_volatility    0.003797\n",
      "last_10min_volatility    0.003647\n",
      "last_5min_volatility     0.002410\n",
      "recent_max               0.002225\n",
      "momentum_10min           0.000758\n",
      "current_reg              0.000728\n",
      "afternoon_avg            0.000440\n",
      "recent_min               0.000178\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importance = pd.Series(logreg.coef_[0], index=X.columns)\n",
    "\n",
    "# Sort by absolute impact\n",
    "importance_sorted = importance.abs().sort_values(ascending=False)\n",
    "print(importance_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a4cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
